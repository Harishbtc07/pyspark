{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-HARISH-REDDY-NEW:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1fc8bfcebd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('..\\pyspark\\Data\\gld_price_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+---------+---------+---------+--------+\n",
      "|     Date|        SPX|      GLD|      USO|      SLV| EUR/USD|\n",
      "+---------+-----------+---------+---------+---------+--------+\n",
      "| 1/2/2008|1447.160034|84.860001|78.470001|    15.18|1.471692|\n",
      "| 1/3/2008|1447.160034|    85.57|78.370003|   15.285|1.474491|\n",
      "| 1/4/2008|1411.630005|85.129997|77.309998|   15.167|1.475492|\n",
      "| 1/7/2008|1416.180054|84.769997|     75.5|   15.053|1.468299|\n",
      "| 1/8/2008|1390.189941|86.779999|76.059998|    15.59|1.557099|\n",
      "| 1/9/2008|1409.130005|86.550003|    75.25|    15.52|1.466405|\n",
      "|1/10/2008|1420.329956|    88.25|74.019997|16.061001|  1.4801|\n",
      "|1/11/2008| 1401.02002|88.580002|73.089996|   16.077|1.479006|\n",
      "|1/14/2008|    1416.25|89.540001|    74.25|16.280001|  1.4869|\n",
      "|1/15/2008|1380.949951|87.989998|72.779999|   15.834| 1.48021|\n",
      "|1/16/2008|1373.199951|86.699997|71.849998|   15.654|1.466405|\n",
      "|1/17/2008|    1333.25|     86.5|71.029999|   15.717|   1.464|\n",
      "|1/18/2008|1325.189941|87.419998|71.540001|16.030001|1.461796|\n",
      "|1/22/2008|     1310.5|88.169998|70.550003|   15.902|1.464794|\n",
      "|1/23/2008|1338.599976|87.889999|     69.5|     15.9|1.463208|\n",
      "|1/24/2008|1352.069946|90.080002|    70.93|16.299999| 1.47741|\n",
      "|1/25/2008|1330.609985|90.300003|71.910004|   16.298|1.467502|\n",
      "|1/28/2008|1353.959961|    91.75|72.349998|16.549999|1.478809|\n",
      "|1/29/2008|1362.300049|91.150002|72.980003|   16.534|1.477192|\n",
      "|1/30/2008|1355.810059|92.059998|73.080002|16.674999|1.483107|\n",
      "+---------+-----------+---------+---------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('..\\pyspark\\Data\\gld_price_data.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='Date', _c1='SPX', _c2='GLD', _c3='USO', _c4='SLV', _c5='EUR/USD'),\n",
       " Row(_c0='1/2/2008', _c1='1447.160034', _c2='84.860001', _c3='78.470001', _c4='15.18', _c5='1.471692'),\n",
       " Row(_c0='1/3/2008', _c1='1447.160034', _c2='85.57', _c3='78.370003', _c4='15.285', _c5='1.474491'),\n",
       " Row(_c0='1/4/2008', _c1='1411.630005', _c2='85.129997', _c3='77.309998', _c4='15.167', _c5='1.475492')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
